{
    "technology": "pytorch",
    "displayName": "PyTorch",
    "category": "LIBRARY",
    "difficulty": "INTERMEDIATE",
    "relations": [
        {
            "to": "python-data",
            "type": "DEPENDS_ON"
        },
        {
            "to": "ml-theory",
            "type": "DEPENDS_ON"
        },
        {
            "to": "ai-math",
            "type": "DEPENDS_ON"
        },
        {
            "to": "tensorflow",
            "type": "ALTERNATIVE_TO"
        },
        {
            "to": "dl-nlp",
            "type": "USED_WITH"
        },
        {
            "to": "dl-vision",
            "type": "USED_WITH"
        },
        {
            "to": "ai-rl",
            "type": "USED_WITH"
        }
    ],
    "documents": [
        {
            "type": "ROADMAP",
            "source": "PyTorch.org Tutorials",
            "content": "# PyTorch 심화 로드맵\n\n## 1. Tensor & Autograd\n- **Dynamic Computation Graph**: 실행 시점에 그래프가 그려짐 (Define-by-Run). 디버깅이 매우 쉬움.\n- `.requires_grad=True`: 미분 추적 시작.\n- `.backward()`: 역전파 수행.\n\n## 2. nn.Module 커스터마이징\n- `__init__`: 레이어 정의.\n- `forward`: 데이터 흐름 정의 (Python 로직 그대로 사용 가능 - if문, for문).\n\n## 3. DataLoader Customization\n- `Dataset` 클래스 상속 (`__len__`, `__getitem__` 구현).\n- `collate_fn`: 배치 단위로 데이터를 묶을 때 커스텀 로직 적용 (Padding 등).\n\n## 4. PyTorch Lightning\n- 학습 루프(Training Loop)의 보일러플레이트 코드를 줄여주는 래퍼 프레임워크.\n- 연구자들 사이에서 표준처럼 사용됨."
        }
    ]
}